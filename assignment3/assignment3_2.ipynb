{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1QamLSsmJyl"
      },
      "source": [
        "**Assignment 3**\n",
        "\n",
        "**By Roll Number 2023702013**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IyKxEbnmJyn"
      },
      "source": [
        "Q1: Face detection and association-based tracking [4.5 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHRnl2b9mJyn"
      },
      "source": [
        "1. Data preparation. We will implement face detection and tracking on a famous scene from the movie Forrest Gump. To prepare the dataset, please download the video clip from https://www.youtube.com/ watch?v=bSMxl1V8FSg (the mp4 at 480p resolution) and burst the first 30 seconds into frames (you should get about 719-720 frames).\n",
        "Hint 1: https://github.com/ytdl-org/youtube-dl is a great tool to download Youtube videos. Use -F flag to identify which format to download.\n",
        "Hint 2: ffmpeg is a wonderful tool to burst the video into frames. But you may also use decord or other libraries for video manipulation (be wary of different frame rates!).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_KttQuqq_jS"
      },
      "outputs": [],
      "source": [
        "file_path='Moviecliop.mp4'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbpXMVv5rZ8F"
      },
      "outputs": [],
      "source": [
        "!ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL639an5mJyo",
        "outputId": "6f8d5631-2534-42cf-e9ab-5637d48e1414"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 11.3.0 (conda-forge gcc 11.3.0-19)\n",
            "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1674566204550/_build_env/bin/pkg-config\n",
            "  libavutil      57. 28.100 / 57. 28.100\n",
            "  libavcodec     59. 37.100 / 59. 37.100\n",
            "  libavformat    59. 27.100 / 59. 27.100\n",
            "  libavdevice    59.  7.100 / 59.  7.100\n",
            "  libavfilter     8. 44.100 /  8. 44.100\n",
            "  libswscale      6.  7.100 /  6.  7.100\n",
            "  libswresample   4.  7.100 /  4.  7.100\n",
            "  libpostproc    56.  6.100 / 56.  6.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data/Movieclip.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: isommp42\n",
            "    creation_time   : 2023-02-02T19:46:38.000000Z\n",
            "  Duration: 00:02:22.11, start: 0.000000, bitrate: 2042 kb/s\n",
            "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], 1911 kb/s, 23.98 fps, 23.98 tbr, 24k tbn (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2023-02-02T19:46:38.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 02/02/2023.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 127 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2023-02-02T19:46:38.000000Z\n",
            "      handler_name    : ISO Media file produced by Google Inc. Created on: 02/02/2023.\n",
            "      vendor_id       : [0][0][0][0]\n",
            "File 'trimmed_video.mp4' already exists. Overwrite? [y/N] "
          ]
        }
      ],
      "source": [
        "#import the frames\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "frames = []\n",
        "video_file='data/Movieclip.mp4'\n",
        "\n",
        "desired_frames = 720\n",
        "total_duration = 30  # seconds\n",
        "fps = desired_frames / total_duration\n",
        "output_folder='data/frames'\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Command to trim the first 30 seconds of the video\n",
        "trim_command = [\n",
        "    \"ffmpeg\",\n",
        "    \"-i\", video_file,\n",
        "    \"-t\", \"00:00:30\",  # Duration of the output clip\n",
        "    \"-c:v\", \"libx264\",  # Video codec to be used\n",
        "    \"-c:a\", \"aac\",  # Audio codec to be used (if you want to keep the audio)\n",
        "    \"trimmed_video.mp4\"\n",
        "]\n",
        "subprocess.run(trim_command)\n",
        "\n",
        "# Command to extract frames at the calculated fps\n",
        "frame_extraction_command = [\n",
        "    \"ffmpeg\",\n",
        "    \"-i\", \"trimmed_video.mp4\",  # Input is the trimmed video\n",
        "    \"-vf\", f\"fps={fps}\",\n",
        "    os.path.join(output_folder, \"frame_%04d.jpg\")\n",
        "]\n",
        "\n",
        "subprocess.run(frame_extraction_command)\n",
        "num_frames = len(os.listdir(output_folder))\n",
        "print(\"Number of frames:\", num_frames)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaUlRzv8mJyp"
      },
      "source": [
        "2. [1.5 points] Face detection. Use the Viola-Jones Haar cascades based face detector from OpenCV to detect faces in each frame. How long does it take to process each frame? Identify some key factors of the algorithm that could change the time.\n",
        "Hint: you may need to look within the xml config file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mb-kI_0XmJyp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
        "face_cascade = cv2.CascadeClassifier(cascade_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G6pjyXQbmJyp"
      },
      "outputs": [],
      "source": [
        "def detect_faces(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "    return faces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQmITikRmJys",
        "outputId": "3db3a8e9-754f-49f8-d463-ee09288d534d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing time: 0.11 ms\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "for frame in frames:\n",
        "    faces = detect_faces(frame)\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "end_time = time.time()\n",
        "print(\"Processing time: {:.2f} ms\".format((end_time - start_time) * 1000))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVmhQJIJmJys",
        "outputId": "c633270b-699f-4a4a-bb37-a5328a4671fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time taken to process frame frame_0001.jpg: 0.4403364658355713 seconds\n",
            "Time taken to process frame frame_0002.jpg: 0.6025142669677734 seconds\n",
            "Time taken to process frame frame_0003.jpg: 0.7894551753997803 seconds\n",
            "Time taken to process frame frame_0004.jpg: 0.7572314739227295 seconds\n",
            "Time taken to process frame frame_0005.jpg: 0.7073864936828613 seconds\n",
            "Time taken to process frame frame_0006.jpg: 0.433211088180542 seconds\n",
            "Time taken to process frame frame_0007.jpg: 0.42881155014038086 seconds\n",
            "Time taken to process frame frame_0008.jpg: 0.43480801582336426 seconds\n",
            "Time taken to process frame frame_0009.jpg: 0.42884230613708496 seconds\n",
            "Time taken to process frame frame_0010.jpg: 0.43456578254699707 seconds\n",
            "Time taken to process frame frame_0011.jpg: 0.41727519035339355 seconds\n",
            "Time taken to process frame frame_0012.jpg: 0.4105961322784424 seconds\n",
            "Time taken to process frame frame_0013.jpg: 0.41927218437194824 seconds\n",
            "Time taken to process frame frame_0014.jpg: 0.410489559173584 seconds\n",
            "Time taken to process frame frame_0015.jpg: 0.42334628105163574 seconds\n",
            "Time taken to process frame frame_0016.jpg: 0.41664934158325195 seconds\n",
            "Time taken to process frame frame_0017.jpg: 0.4281134605407715 seconds\n",
            "Time taken to process frame frame_0018.jpg: 0.4285309314727783 seconds\n",
            "Time taken to process frame frame_0019.jpg: 0.42635178565979004 seconds\n",
            "Time taken to process frame frame_0020.jpg: 0.426485538482666 seconds\n",
            "Time taken to process frame frame_0021.jpg: 0.42140793800354004 seconds\n",
            "Time taken to process frame frame_0022.jpg: 0.42646217346191406 seconds\n",
            "Time taken to process frame frame_0023.jpg: 0.4374372959136963 seconds\n",
            "Time taken to process frame frame_0024.jpg: 0.4291665554046631 seconds\n",
            "Time taken to process frame frame_0025.jpg: 0.41660046577453613 seconds\n",
            "Time taken to process frame frame_0026.jpg: 0.4387493133544922 seconds\n",
            "Time taken to process frame frame_0027.jpg: 0.5252580642700195 seconds\n",
            "Time taken to process frame frame_0028.jpg: 0.735560417175293 seconds\n",
            "Time taken to process frame frame_0029.jpg: 0.7179152965545654 seconds\n",
            "Time taken to process frame frame_0030.jpg: 0.6051435470581055 seconds\n",
            "Time taken to process frame frame_0031.jpg: 0.5205380916595459 seconds\n",
            "Time taken to process frame frame_0032.jpg: 0.40795469284057617 seconds\n",
            "Time taken to process frame frame_0033.jpg: 0.4459409713745117 seconds\n",
            "Time taken to process frame frame_0034.jpg: 0.41741371154785156 seconds\n",
            "Time taken to process frame frame_0035.jpg: 0.43706297874450684 seconds\n",
            "Time taken to process frame frame_0036.jpg: 0.4177424907684326 seconds\n",
            "Time taken to process frame frame_0037.jpg: 0.4377555847167969 seconds\n",
            "Time taken to process frame frame_0038.jpg: 0.40010643005371094 seconds\n",
            "Time taken to process frame frame_0039.jpg: 0.42018818855285645 seconds\n",
            "Time taken to process frame frame_0040.jpg: 0.40822339057922363 seconds\n",
            "Time taken to process frame frame_0041.jpg: 0.4064786434173584 seconds\n",
            "Time taken to process frame frame_0042.jpg: 0.4210832118988037 seconds\n",
            "Time taken to process frame frame_0043.jpg: 0.4005749225616455 seconds\n",
            "Time taken to process frame frame_0044.jpg: 0.42321228981018066 seconds\n",
            "Time taken to process frame frame_0045.jpg: 0.396914005279541 seconds\n",
            "Time taken to process frame frame_0046.jpg: 0.4061126708984375 seconds\n",
            "Time taken to process frame frame_0047.jpg: 0.3958249092102051 seconds\n",
            "Time taken to process frame frame_0048.jpg: 0.399669885635376 seconds\n",
            "Time taken to process frame frame_0049.jpg: 0.4130387306213379 seconds\n",
            "Time taken to process frame frame_0050.jpg: 0.5740916728973389 seconds\n",
            "Time taken to process frame frame_0051.jpg: 0.5861043930053711 seconds\n",
            "Time taken to process frame frame_0052.jpg: 0.6998887062072754 seconds\n",
            "Time taken to process frame frame_0053.jpg: 0.9828026294708252 seconds\n",
            "Time taken to process frame frame_0054.jpg: 0.8945326805114746 seconds\n",
            "Time taken to process frame frame_0055.jpg: 0.7785236835479736 seconds\n",
            "Time taken to process frame frame_0056.jpg: 0.5690274238586426 seconds\n",
            "Time taken to process frame frame_0057.jpg: 0.5927670001983643 seconds\n",
            "Time taken to process frame frame_0058.jpg: 0.5783207416534424 seconds\n",
            "Time taken to process frame frame_0059.jpg: 0.5896546840667725 seconds\n"
          ]
        }
      ],
      "source": [
        "frames_folder='data/frames'\n",
        "tot_time=0\n",
        "for i,frame_file in enumerate(sorted(os.listdir(frames_folder))):\n",
        "    frame_path = os.path.join(frames_folder, frame_file)\n",
        "    frame = cv2.imread(frame_path)\n",
        "\n",
        "    # Convert the frame to grayscale for face detection\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Perform face detection\n",
        "    start_time = time.time()\n",
        "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=15, minSize=(30, 30))\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Draw rectangles around the detected faces\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "    # Calculate and print the time taken to process each frame\n",
        "    processing_time = end_time - start_time\n",
        "    print(f\"Time taken to process frame {frame_file}: {processing_time} seconds\")\n",
        "\n",
        "    # Write the processed frame to the output directory\n",
        "    output_filename = f'data/output/frame_{i}.png'\n",
        "    cv2.imwrite(output_filename, frame)\n",
        "\n",
        "    tot_time += processing_time\n",
        "\n",
        "print('Total time taken:', tot_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHwPPl6ZmJys"
      },
      "source": [
        "3. Face detection visualization. Visualize the face detections made over the first 30s frames as a new video. Link to the video from your google drive. Watch the video and draw three conclusions about when does the face detector work or fail. Why do you think this is the case?\n",
        "Hint: You can use cv2.rectangle to draw boxes on the image and then save them back to disk. Then ffmpeg can be used again to stitch together the frames into a new video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH4pFMW4mJys",
        "outputId": "74b3404c-c3b4-4bb1-8f1d-531001c71eaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;35m[image2 @ 0x55c8cf2ab180] \u001b[0m\u001b[1;31mCould find no file with path 'processed_frames/frame_%03d.jpg' and index in the range 0-4\n",
            "\u001b[0m\u001b[1;31mprocessed_frames/frame_%03d.jpg: No such file or directory\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!ffmpeg -framerate 24 -i processed_frames/frame_%03d.jpg -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p output_video.mp4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6CFWFVAmJys"
      },
      "source": [
        "4. [1.5 point] Association-based tracking. Tracking can be used to associate face detections across time and understand that it is the same character appearing across multiple frames of the movie. We will explore a simple way to perform tracking.\n",
        "(i) Generate face tracks by comparing face detections in two consecutive frames and associating them based on IoU scores. You may want to associate faces only when IoU > 0.5. Do consider what happens when there are multiple face detections in both frames. Start new tracks for faces not seen in the previous frame. End existing tracks when faces are not visible in the next frame. How many unique tracks did you create in the first 30 seconds?\n",
        "(ii) Update the video visualization above to now include a unique track identifier (an integer number is fine), shown inside each box. Link to the video from your google drive.\n",
        "Hint: You may use cv2.putText to write these numbers. Make sure they are readable after stitching together the frames into a video.\n",
        "(iii) Comment about the quality of the face tracks. Do different people get associated in one track? Is a unique character associated with one unique track id? Note the timestamps of some failure cases and explain why."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "newenvt",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
